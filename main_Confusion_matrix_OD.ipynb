{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix for CocoAPI\n",
    "\n",
    "The \"main_Evaluate_Object_Detection.ipynb\" uses the CocoApi to evaluate the model performance, e.g., AP50. But that code does not include the output of confusion matrix (e.g., TP, FP, and FN).\n",
    "\n",
    "This script provides the output of confusion matrix using **FiftyOne** tool\n",
    "\n",
    "FiftyOne’s implementation of COCO-style evaluation matches the reference implementation available via pycocotools (https://github.com/cocodataset/cocoapi).\n",
    "\n",
    "Refer to: \n",
    "https://docs.voxel51.com/integrations/coco.html#loading-coco-formatted-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install fiftyone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   For windows:\n",
    "#        pip3 install fiftyone --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load coco dataset (ground-truth)\n",
    "\n",
    "**Note**: \n",
    "\n",
    "(1) the folder/path of images in json file must contains \" / \" instead of \" \\ \" \n",
    "\n",
    "(2) In json file, \"image_id\" and the \"id\" for annotations must not start \"0\", otherwise the results will be not correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████████| 6/6 [85.9ms elapsed, 0s remaining, 69.9 samples/s]      \n",
      "Name:        2024.11.05.23.54.57\n",
      "Media type:  image\n",
      "Num samples: 6\n",
      "Persistent:  False\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:         fiftyone.core.fields.ObjectIdField\n",
      "    filepath:   fiftyone.core.fields.StringField\n",
      "    tags:       fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:   fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    detections: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "# A name for the dataset\n",
    "# name = \"my-dataset\"\n",
    "\n",
    "# # # 0609 all images\n",
    "# image_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0609/images_with_litter/\"\n",
    "# labels_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0609/annotations/0609_1_class.json\"\n",
    "\n",
    "# # # 0609_1_round test dataset\n",
    "# image_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0609/1_round_test/images_with_litter/\"\n",
    "# labels_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0609/1_round_test/annotations/0609_1_round.json\"\n",
    "\n",
    "# # # val dataset\n",
    "# image_path = r\"/scratch/tjian/Data/Flux/labeled_images/val/\"\n",
    "# labels_path = r\"/scratch/tjian/Data/Flux/labeled_images/annotations/val.json\"\n",
    "\n",
    "# # Exp_1: test dataset\n",
    "# image_path = r\"/scratch/tjian/Data/Flux/labeled_images_new/test/\"\n",
    "# labels_path = r\"/scratch/tjian/Data/Flux/labeled_images_new/annotations/test.json\"\n",
    "\n",
    "# 0909 labeled data\n",
    "# image_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/images_with_litter/\"\n",
    "# labels_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/annotations/0909.json\"\n",
    "\n",
    "# 1209 labeled data\n",
    "image_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/images_with_litter/\"\n",
    "labels_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/annotations/1209.json\"\n",
    "\n",
    "# # 1209_Sweep_1_5\n",
    "# image_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/Sweep_4_5/images/\"\n",
    "# labels_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/Sweep_4_5/Sweep_4_5.json\"\n",
    "\n",
    "# The type of the dataset being imported\n",
    "dataset_type = fo.types.COCODetectionDataset  # coco format\n",
    "\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_type=dataset_type,\n",
    "    data_path=image_path,\n",
    "    labels_path=labels_path,\n",
    "    # include_id=True,\n",
    "    # name=name,\n",
    ")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Detection: {\n",
      "    'id': '672a3fd15331c8603281a4de',\n",
      "    'attributes': {},\n",
      "    'tags': [],\n",
      "    'label': 'litter',\n",
      "    'bounding_box': [0.077128, 0.3703245, 0.035904000000000005, 0.088529],\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "    'iscrowd': 0.0,\n",
      "    'segmented': None,\n",
      "    'pose': None,\n",
      "    'truncated': None,\n",
      "    'difficult': None,\n",
      "}>\n"
     ]
    }
   ],
   "source": [
    "# show the first data in the dataset,\n",
    "# Carefully check the \"label\" name!\n",
    "# Note the coordinates of the bbox is scaled into [0,1]\n",
    "\n",
    "print(dataset.first().detections.detections[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load predictions\n",
    "\n",
    "When inferencing a model on a test dataset using Detectron2, it will output a prediction file named \"coco_instances_results.json\" with predicted bbox\n",
    "\n",
    "Note: when load predictions in a json file, the \"id\" in \"images\" field must start from **\"1\"**, Otherwise it will not work. You may use to change the \"id in json using: *https://github.com/TianlongJia/Tools/tree/master/Vision/Manage_pic_and_folder//Modify_JSON.ipynb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes: ['0', 'litter']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import fiftyone.utils.coco as fouc\n",
    "import json\n",
    "\n",
    "#\n",
    "# Mock COCO predictions, where:\n",
    "# - `image_id` corresponds to the `coco_id` field of `coco_dataset`\n",
    "# - `category_id` corresponds to classes in `coco_dataset.default_classes`\n",
    "#\n",
    "# predictions = [\n",
    "#     {\"image_id\": 1, \"category_id\": 18, \"bbox\": [258, 41, 348, 243], \"score\": 0.87},\n",
    "#     {\"image_id\": 2, \"category_id\": 11, \"bbox\": [61, 22, 504, 609], \"score\": 0.95},\n",
    "# ]\n",
    "\n",
    "# json_file= r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/Sweep_4_5/Pred/results_new.json\"\n",
    "json_file= r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/Pred/SSL_100per_1/No_SA/test_results/coco_instances_results.json\"\n",
    "with open(json_file, 'r') as fcc_file:\n",
    "    fcc_data = json.load(fcc_file)\n",
    "\n",
    "# Assign the JSON data to predictions\n",
    "predictions = fcc_data\n",
    "\n",
    "# Add COCO predictions to `predictions` field of dataset\n",
    "classes = dataset.default_classes\n",
    "print(\"classes:\", classes)\n",
    "# classes = ['hold_space', 'litter',]\n",
    "# classes = ['airplane', 'apple', ...]\n",
    "fouc.add_coco_labels(dataset, \"predictions\", predictions, classes)\n",
    "\n",
    "# Verify that predictions were added to two images\n",
    "print(dataset.count(\"predictions\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image_id': 6,\n",
       "  'bbox': [4341.59765625,\n",
       "   1729.8573913574219,\n",
       "   320.1187744140625,\n",
       "   385.6191101074219],\n",
       "  'score': 0.9335148334503174,\n",
       "  'category_id': 1,\n",
       "  'category_name': 'litter',\n",
       "  'segmentation': [],\n",
       "  'iscrowd': 0,\n",
       "  'area': 123443},\n",
       " {'image_id': 8,\n",
       "  'bbox': [4682.675598144531,\n",
       "   1489.52490234375,\n",
       "   318.06622314453125,\n",
       "   385.38885498046875],\n",
       "  'score': 0.9758250713348389,\n",
       "  'category_id': 1,\n",
       "  'category_name': 'litter',\n",
       "  'segmentation': [],\n",
       "  'iscrowd': 0,\n",
       "  'area': 122579},\n",
       " {'image_id': 8,\n",
       "  'bbox': [2004.1599426269531,\n",
       "   550.317138671875,\n",
       "   295.1063537597656,\n",
       "   480.26123046875],\n",
       "  'score': 0.9576756954193115,\n",
       "  'category_id': 1,\n",
       "  'category_name': 'litter',\n",
       "  'segmentation': [],\n",
       "  'iscrowd': 0,\n",
       "  'area': 141728},\n",
       " {'image_id': 8,\n",
       "  'bbox': [1090.276123046875,\n",
       "   30.460670471191406,\n",
       "   783.155517578125,\n",
       "   581.8568344116211],\n",
       "  'score': 0.955977737903595,\n",
       "  'category_id': 1,\n",
       "  'category_name': 'litter',\n",
       "  'segmentation': [],\n",
       "  'iscrowd': 0,\n",
       "  'area': 455684},\n",
       " {'image_id': 9,\n",
       "  'bbox': [1537.9938629865646,\n",
       "   1270.3848876953125,\n",
       "   281.213076710701,\n",
       "   325.2138671875],\n",
       "  'score': 0.9974018335342407,\n",
       "  'category_id': 1,\n",
       "  'category_name': 'litter',\n",
       "  'segmentation': [],\n",
       "  'iscrowd': 0,\n",
       "  'area': 91454},\n",
       " {'image_id': 9,\n",
       "  'bbox': [1453.1666259765625, 1420.0, 414.2900390625, 160.69668579101562],\n",
       "  'score': 0.9610167741775513,\n",
       "  'category_id': 1,\n",
       "  'category_name': 'litter',\n",
       "  'segmentation': [],\n",
       "  'iscrowd': 0,\n",
       "  'area': 66575},\n",
       " {'image_id': 10,\n",
       "  'bbox': [5318.034423828125,\n",
       "   1995.3742980957031,\n",
       "   370.1632080078125,\n",
       "   339.6374816894531],\n",
       "  'score': 0.9777874946594238,\n",
       "  'category_id': 1,\n",
       "  'category_name': 'litter',\n",
       "  'segmentation': [],\n",
       "  'iscrowd': 0,\n",
       "  'area': 125721},\n",
       " {'image_id': 10,\n",
       "  'bbox': [2169.179931640625,\n",
       "   2576.232666015625,\n",
       "   3846.820068359375,\n",
       "   1093.4619140625],\n",
       "  'score': 0.9341484308242798,\n",
       "  'category_id': 1,\n",
       "  'category_name': 'litter',\n",
       "  'segmentation': [],\n",
       "  'iscrowd': 0,\n",
       "  'area': 4206351},\n",
       " {'image_id': 10,\n",
       "  'bbox': [4123.978626251221,\n",
       "   869.5936279296875,\n",
       "   720.1879997253418,\n",
       "   649.7730712890625],\n",
       "  'score': 0.9240583181381226,\n",
       "  'category_id': 1,\n",
       "  'category_name': 'litter',\n",
       "  'segmentation': [],\n",
       "  'iscrowd': 0,\n",
       "  'area': 467958},\n",
       " {'image_id': 10,\n",
       "  'bbox': [2011.8164367675781,\n",
       "   1428.491455078125,\n",
       "   231.49520874023438,\n",
       "   349.3389892578125],\n",
       "  'score': 0.9170367121696472,\n",
       "  'category_id': 1,\n",
       "  'category_name': 'litter',\n",
       "  'segmentation': [],\n",
       "  'iscrowd': 0,\n",
       "  'area': 80870},\n",
       " {'image_id': 11,\n",
       "  'bbox': [3264.258987426758,\n",
       "   2018.4277954101562,\n",
       "   597.9671478271484,\n",
       "   697.5828247070312],\n",
       "  'score': 0.9957738518714905,\n",
       "  'category_id': 1,\n",
       "  'category_name': 'litter',\n",
       "  'segmentation': [],\n",
       "  'iscrowd': 0,\n",
       "  'area': 417131},\n",
       " {'image_id': 11,\n",
       "  'bbox': [2794.67138671875,\n",
       "   1844.642578125,\n",
       "   1090.993896484375,\n",
       "   932.1708984375],\n",
       "  'score': 0.9281420111656189,\n",
       "  'category_id': 1,\n",
       "  'category_name': 'litter',\n",
       "  'segmentation': [],\n",
       "  'iscrowd': 0,\n",
       "  'area': 1016992}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n"
     ]
    }
   ],
   "source": [
    "print(dataset.count(\"detections\"))  # the number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first data (with prediction bbox) in the dataset ,\n",
    "# Carefully check the \"label\" name!\n",
    "# Note the coordinates of the predicted bbox is scaled into [0,1]\n",
    "\n",
    "# print(dataset.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = dataset.first()\n",
    "# print(sample.detections.detections[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output results \n",
    "\n",
    "by comparing ground-truth labels and predictions bbox\n",
    "\n",
    "**Note**: Predicted and ground truth objects are matched using a specified IoU threshold (default = 0.50). This threshold can be customized via the iou parameter. The IoU selection affects the calculation of TP, FN, are FP value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n",
      " 100% |█████████████████████| 6/6 [77.6ms elapsed, 0s remaining, 77.3 samples/s] \n",
      "Performing IoU sweep...\n",
      " 100% |█████████████████████| 6/6 [74.1ms elapsed, 0s remaining, 81.0 samples/s] \n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "# Evaluate the objects in the `predictions` field with respect to the\n",
    "# objects in the `ground_truth` field\n",
    "results = dataset.evaluate_detections(\n",
    "    \"predictions\",\n",
    "    gt_field=\"detections\",\n",
    "    iou=0.5,\n",
    "    method=\"coco\",   \n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fiftyone.utils.eval.coco.COCODetectionResults at 0x16ecbabb910>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mAP\n",
    "\n",
    "Note: this is the mAP at IoU=.50:.05:.95\n",
    "\n",
    "https://docs.voxel51.com/user_guide/evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(results.mAP())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total TP, FP, FN\n",
    "\n",
    "Note: the calculation of these metrics follows the IoU pre-defined above:\n",
    "\n",
    "i.e., results = dataset.evaluate_detections(..., iou=XXX, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 0\n",
      "FP: 1\n",
      "FN: 24\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics about the total TP/FP/FN counts\n",
    "print(\"TP: %d\" % dataset.sum(\"eval_tp\"))\n",
    "print(\"FP: %d\" % dataset.sum(\"eval_fp\"))\n",
    "print(\"FN: %d\" % dataset.sum(\"eval_fn\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TP, FP, FN for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each sample in the dataset and print TP, FP, FN for each image\n",
    "for sample in dataset:\n",
    "    image_id = sample.id\n",
    "    image_path = sample.filepath\n",
    "    tp = sample[\"eval_tp\"] if \"eval_tp\" in sample else 0\n",
    "    fp = sample[\"eval_fp\"] if \"eval_fp\" in sample else 0\n",
    "    fn = sample[\"eval_fn\"] if \"eval_fn\" in sample else 0\n",
    "    print(f\"Image ID: {image_id}\")\n",
    "    print(f\"Image Path: {image_path}\")\n",
    "    print(f\"TP: {tp}, FP: {fp}, FN: {fn}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, recall, F1-score\n",
    "\n",
    "Note: the calculation of these metrics follows the IoU pre-defined above:\n",
    "\n",
    "i.e., results = dataset.evaluate_detections(..., iou=XXX, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      litter       0.00      0.00      0.00      24.0\n",
      "\n",
      "   micro avg       0.00      0.00      0.00      24.0\n",
      "   macro avg       0.00      0.00      0.00      24.0\n",
      "weighted avg       0.00      0.00      0.00      24.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes = 1\n",
    "counts = dataset.count_values(\"detections.detections.label\")\n",
    "classes = sorted(counts, key=counts.get, reverse=True)[:classes]\n",
    "\n",
    "# Print a classification report for the top-10 classes\n",
    "results.print_report(classes=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = results.plot_pr_curves(classes=[\"litter\"])\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "\n",
    "# Perform evaluation, allowing objects to be matched between classes\n",
    "results = dataset.evaluate_detections(\n",
    "    \"predictions\",\n",
    "    gt_field=\"detections\",\n",
    "    method=\"coco\",\n",
    "    classwise=False,\n",
    ")\n",
    "\n",
    "# Generate a confusion matrix for the specified classes\n",
    "plot = results.plot_confusion_matrix(classes=[\"litter\"])\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.utils.coco as fouc\n",
    "import json\n",
    "import os\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "\n",
    "# # 0909 labeled data\n",
    "# image_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/images_with_litter/\"\n",
    "# labels_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/annotations/0909.json\"\n",
    "\n",
    "# # 1209 labeled data\n",
    "image_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/images_with_litter/\"\n",
    "labels_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/annotations/1209.json\"\n",
    "\n",
    "# The type of the dataset being imported\n",
    "dataset_type = fo.types.COCODetectionDataset  # coco format\n",
    "\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_type=dataset_type,\n",
    "    data_path=image_path,\n",
    "    labels_path=labels_path,\n",
    ")\n",
    "print(dataset)\n",
    "\n",
    "root_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/Pred/SSL_20per_2_to_10/SA_1920_Conf_0.9/With_litter/\"\n",
    "folders = os.listdir(root_path)\n",
    "\n",
    "for folder in folders:\n",
    "    print(\"#################\", folder, \"#################\")\n",
    "    json_file = os.path.join(root_path, folder, \"results_new.json\")\n",
    "    print(json_file)\n",
    "    with open(json_file, 'r') as fcc_file:\n",
    "      fcc_data = json.load(fcc_file)\n",
    "    predictions = fcc_data\n",
    "    classes = dataset.default_classes\n",
    "    print(\"classes:\", classes)\n",
    "    fouc.add_coco_labels(dataset, \"predictions\", predictions, classes)\n",
    "    results = dataset.evaluate_detections(\n",
    "        \"predictions\",\n",
    "        gt_field=\"detections\",\n",
    "        iou=0.5,\n",
    "        method=\"coco\",   \n",
    "        eval_key=\"eval\",\n",
    "        compute_mAP=True,\n",
    "        )\n",
    "    print(results.mAP())\n",
    "    \n",
    "    print(\"TP: %d\" % dataset.sum(\"eval_tp\"))\n",
    "    print(\"FP: %d\" % dataset.sum(\"eval_fp\"))\n",
    "    print(\"FN: %d\" % dataset.sum(\"eval_fn\"))\n",
    "    classes = 1\n",
    "    counts = dataset.count_values(\"detections.detections.label\")\n",
    "    classes = sorted(counts, key=counts.get, reverse=True)[:classes]\n",
    "    results.print_report(classes=classes)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
