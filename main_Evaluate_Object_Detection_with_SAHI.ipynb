{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W65GPvi1XDsl"
      },
      "source": [
        "# Oject detection evaluation with SAHI\n",
        "\n",
        "Test a Detector on A Customized Dataset (here, I use the Faster RCNN)\n",
        "\n",
        "https://github.com/obss/sahi\n",
        "\n",
        "https://medium.com/voxel51/how-to-detect-small-objects-cfa569b4d5bd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCl2HeNi0wfY"
      },
      "source": [
        "- Import required modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "\n",
        "from sahi.utils.detectron2 import Detectron2TestConstants\n",
        "\n",
        "# import required functions, classes\n",
        "from sahi import AutoDetectionModel\n",
        "from sahi.predict import get_sliced_prediction, predict, get_prediction\n",
        "from sahi.utils.file import download_from_url\n",
        "from sahi.utils.cv import read_image\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the custom model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNpMx3Au0rgO"
      },
      "outputs": [],
      "source": [
        "# # baseline model path\n",
        "# model_checkpoint_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/RN50_300K/Exp2/RN50_300K_100e/SSL_F4/model_best_86.1242.pth\"\n",
        "# model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/RN50_300K/Exp2/RN50_300K_100e/SSL_F4/config.yaml\"\n",
        "\n",
        "# ANI\n",
        "# model path\n",
        "model_checkpoint_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/RN50_300K/Exp2/RN50_300K_100e/SSL_F4_ANI/model_best_85.2134.pth\"\n",
        "model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/RN50_300K/Exp2/RN50_300K_100e/SSL_F4_ANI/config.yaml\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register my custom train and test dataset\n",
        "\n",
        "dataset should be in COCO format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Register a test dataset\n",
        "\n",
        "# # Baseline model\n",
        "# register_coco_instances(\"Flux_train\", {}, \"/scratch/tjian/Data/Flux/labeled_images/annotations/train.json\", \"/scratch/tjian/Data/Flux/labeled_images/train/\")\n",
        "# register_coco_instances(\"Flux_val\", {}, \"/scratch/tjian/Data/Flux/labeled_images/annotations/val.json\", \"/scratch/tjian/Data/Flux/labeled_images/val/\")\n",
        "# Train_Dataset_name=\"Flux_train\"\n",
        "# Test_Dataset_name=\"Flux_val\"\n",
        "# Class_name=[\"litter\"]\n",
        "\n",
        "# Flux_train_added_0609_datat (original train:val=80%:20%)\n",
        "register_coco_instances(\"Flux_train_ANI\", {}, \"/scratch/tjian/Data/Flux/labeled_and_added_new/annotations/train.json\", \"/scratch/tjian/Data/Flux/labeled_and_added_new/train/\")\n",
        "register_coco_instances(\"Flux_val_ANI\", {}, \"/scratch/tjian/Data/Flux/labeled_and_added_new/annotations/val.json\", \"/scratch/tjian/Data/Flux/labeled_and_added_new/val/\")\n",
        "Train_Dataset_name=\"Flux_train_ANI\"\n",
        "Test_Dataset_name=\"Flux_val_ANI\"\n",
        "Class_name=[\"litter\"]\n",
        "\n",
        "\n",
        "\n",
        "MetadataCatalog.get(Train_Dataset_name).set(thing_classes=Class_name)\n",
        "MetadataCatalog.get(Test_Dataset_name).set(thing_classes=Class_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build a detection model\n",
        "\n",
        "Instantiate a detection model by defining model weight path, confing path and other parameters.\n",
        "\n",
        "This model will be used to inference in slicing images or original images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \"image_size\": Input image size for each inference (image is scaled by preserving aspect ratio).\n",
        "# there is no default \"image_size\". \n",
        "# So if not set \"image_size\", the image will be resized by the setting in the model config file\n",
        "\n",
        "# \"device\": (1) \"cpu\", or (2) 'cuda:0'\n",
        "\n",
        "detection_model = AutoDetectionModel.from_pretrained(\n",
        "    model_type='detectron2',\n",
        "    model_path=model_checkpoint_path,\n",
        "    config_path=model_config_path,\n",
        "    confidence_threshold=0.9,\n",
        "    # image_size=1333,\n",
        "    device=\"cuda:0\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1 Predict an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define image path\n",
        "image_path=r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0609/images_with_litter/BL_2023_09_06_Sweep_1_5_DCSS0262.jpg\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.1 Standard Inference with a Detectron2 Model\n",
        "\n",
        "- Perform prediction by feeding the get_prediction function with an image path and a DetectionModel instance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "export_dir=r\"/scratch/tjian/Data/Flux/TUD_Vietnam/test/\"\n",
        "output_file_name=\"BL_2023_09_06_Sweep_1_5_DCSS0262\"   # do not end with \"\".jpg\n",
        "\n",
        "result = get_prediction(image_path, detection_model)\n",
        "result.export_visuals(export_dir, \n",
        "                      text_size=3, # float\n",
        "                      file_name=output_file_name)\n",
        "\n",
        "# output No. detections\n",
        "num_orig_dets = len(result.to_fiftyone_detections())\n",
        "print(f\"Detections predicted without slicing: {num_orig_dets}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9Y2kCRz6Y74"
      },
      "source": [
        "#### 1.2 Sliced Inference with a Detectron2 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPsuXa_R6gKl"
      },
      "source": [
        "- To perform sliced prediction we need to specify slice parameters. In this example we will perform prediction over slices of slice_width*slice_height (e.g.,256x256) with an overlap ratio of 0.2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM6uCgAS6Ze4",
        "outputId": "a703b758-0141-4ac7-f7b2-0804f7b10070"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing prediction on 15 number of slices.\n"
          ]
        }
      ],
      "source": [
        "export_dir=r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0609/Predict/R50_300K_100e/SAHI/test/\"\n",
        "output_file_name= \"BL_2023_09_06_Sweep_1_5_DCSS0262\"   # do not end with \"\".jpg\n",
        "\n",
        "result = get_sliced_prediction(\n",
        "    image_path,\n",
        "    detection_model,\n",
        "    slice_height = 640,\n",
        "    slice_width = 640,\n",
        "    overlap_height_ratio = 0.2,\n",
        "    overlap_width_ratio = 0.2,\n",
        ")\n",
        "\n",
        "result.export_visuals(export_dir, \n",
        "                      text_size=3,\n",
        "                      file_name=output_file_name)\n",
        "\n",
        "# output No. detections\n",
        "num_sliced_dets = len(result.to_fiftyone_detections())\n",
        "print(f\"Detections predicted with slicing: {num_sliced_dets}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2 Predict images in a folder (Sliced Inference)\n",
        "\n",
        "Output:\n",
        "\n",
        "(1) predicted images (the code will save the predicted images in a subfolder named *\"pred_images\"*); \n",
        "\n",
        "(2) A excel file named *\"detection_results.xlsx\"*, stores filename and No.detections\n",
        "\n",
        "(3) Print the total number of detections in the console\n",
        "\n",
        "\"postprocess_type\": Options are 'NMM', 'GREEDYNMM', 'LSNMS' or 'NMS'. Default is 'GREEDYNMM'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "source_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/images_no_litter/\"\n",
        "# source_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/images_no_litter/\"\n",
        "\n",
        "# do not generate the output_dir, the code will do it automatically\n",
        "output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/ANI_Pred_images_no_litter\"\n",
        "# output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/ANI_Pred_images_no_litter\"\n",
        "\n",
        "# define slicing conf.\n",
        "slice_height = 1280\n",
        "slice_width = 1280\n",
        "overlap_height_ratio = 0.2\n",
        "overlap_width_ratio = 0.2\n",
        "\n",
        "# Perform sliced inference on given folder\n",
        "# it will also output the (total) number of detections in each/all images\n",
        "result = predict(\n",
        "    detection_model = detection_model,\n",
        "    source = source_image_dir,\n",
        "    slice_height = slice_height,\n",
        "    slice_width = slice_width,\n",
        "    overlap_height_ratio = overlap_height_ratio,\n",
        "    overlap_width_ratio = overlap_width_ratio,\n",
        "    project = output_dir,\n",
        "    postprocess_type = 'NMS', # dDefault is 'GREEDYNMM'.\n",
        "    postprocess_match_metric = 'IOU',\n",
        "    postprocess_match_threshold = 0.3, # NMS_IoU_threshold\n",
        "    visual_text_size = 3 # float\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3 Evaluate in a labeled dataset\n",
        "\n",
        "In the output path, the code generates:ã€€\n",
        "\n",
        "(1) predicted images (the code will save the predicted images in a subfolder named *\"pred_images\"*); \n",
        "\n",
        "(2) a subfolder named *\"visuals_with_gt\"* including images with ground-truth and predictions;\n",
        "\n",
        "(3) a json file \"results.json\" including prediction results;\n",
        "\n",
        "(4) A excel file named *\"detection_results.xlsx\"*, stores filename and No.detections\n",
        "\n",
        "(5) Print the total number of detections in the console"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1 Processing images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/images_with_litter/\"\n",
        "# test_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/images_with_litter/\"\n",
        "\n",
        "# test dataset (with annotations)\n",
        "test_annotation_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/annotations/0909.json\"\n",
        "# test_annotation_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/annotations/1209.json\"\n",
        "\n",
        "\n",
        "# do not generate the output_dir, the code will do it automatically\n",
        "output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/ANI_Pred_images_with_litter/\"\n",
        "# output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/ANI_Pred_images_with_litter/\"\n",
        "\n",
        "# define slicing conf.\n",
        "slice_height = 1280\n",
        "slice_width = 1280\n",
        "overlap_height_ratio = 0.2\n",
        "overlap_width_ratio = 0.2\n",
        "\n",
        "# Perform sliced inference on given folder:\n",
        "# it will also output the (total) number of detections in each/all images\n",
        "predict(\n",
        "    detection_model = detection_model,\n",
        "    source = test_image_dir,\n",
        "    slice_height = slice_height,\n",
        "    slice_width = slice_width,\n",
        "    overlap_height_ratio = overlap_height_ratio,\n",
        "    overlap_width_ratio = overlap_width_ratio,\n",
        "    project = output_dir,\n",
        "    dataset_json_path = test_annotation_path,\n",
        "    postprocess_type = 'NMS', # dDefault is 'GREEDYNMM'.\n",
        "    postprocess_match_metric = 'IOU',\n",
        "    postprocess_match_threshold = 0.3, # NMS_IoU_threshold\n",
        "    visual_text_size = 3 # float\n",
        "    # visual_bbox_thickness = None  # init\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.2 Modify the output json file\n",
        "\n",
        "Note: the \"results.json\" file output in the above code (1) has an issue of category. \n",
        "\n",
        "By default, Detectron2 or SAHI starts the category_id from \"0\". But the category_id starts from \"1\" in my input annotation file. \n",
        "\n",
        "Thus, it is **necessary** that all category IDs are incremented by 1 in the output json file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "input_json = r'/scratch/tjian/Data/Flux/TUD_Vietnam/0909/ANI_Pred_images_with_litter/results.json'\n",
        "output_json = r'/scratch/tjian/Data/Flux/TUD_Vietnam/0909/ANI_Pred_images_with_litter/results_new.json'\n",
        "\n",
        "# Read the JSON file\n",
        "with open(input_json, 'r') as file:\n",
        "    coco_data = json.load(file)\n",
        "\n",
        "# Check if the JSON structure is a list or a dictionary\n",
        "if isinstance(coco_data, list):\n",
        "    # Assume the list contains annotation dictionaries directly\n",
        "    for annotation in coco_data:\n",
        "        annotation['category_id'] += 1\n",
        "else:\n",
        "    # Assume it's a dictionary with an 'annotations' key\n",
        "    for annotation in coco_data.get('annotations', []):\n",
        "        annotation['category_id'] += 1\n",
        "\n",
        "# Save the modified JSON to a new file\n",
        "with open(output_json, 'w') as file:\n",
        "    json.dump(coco_data, file, indent=4)\n",
        "\n",
        "print(f\"All category IDs have been incremented by 1 and saved to {output_json}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.3 Output evaulation metrics in \"main_Confusion_matrix_OD.ipynb\"\n",
        "\n",
        "e.g., mAP, TP, FP, FN, precision, recall, F1-score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwn78AeP6rVK"
      },
      "source": [
        "### 3. To do: Prediction Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BG-je0V6uCn"
      },
      "source": [
        "- Predictions are returned as [sahi.prediction.PredictionResult](sahi/prediction.py), you can access the object prediction list as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4mpkIu66ZkQ"
      },
      "outputs": [],
      "source": [
        "object_prediction_list = result.object_prediction_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gjXS1FY6Zm4",
        "outputId": "3d6ac27e-61a4-44d4-c03b-a25fce54b513"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ObjectPrediction<\n",
              "    bbox: BoundingBox: <(656, 197, 671, 215), w: 15, h: 18>,\n",
              "    mask: None,\n",
              "    score: PredictionScore: <value: 0.9950496554374695>,\n",
              "    category: Category: <id: 2, name: car>>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "object_prediction_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61sUXOyZ6Zp1",
        "outputId": "98951632-198c-4760-bbbd-19ff3eb3be65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'image_id': None,\n",
              "  'bbox': [656, 197, 15, 18],\n",
              "  'score': 0.9950494170188904,\n",
              "  'category_id': 2,\n",
              "  'category_name': 'car',\n",
              "  'segmentation': [],\n",
              "  'iscrowd': 0,\n",
              "  'area': 270},\n",
              " {'image_id': None,\n",
              "  'bbox': [446, 308, 49, 34],\n",
              "  'score': 0.9942395687103271,\n",
              "  'category_id': 2,\n",
              "  'category_name': 'car',\n",
              "  'segmentation': [],\n",
              "  'iscrowd': 0,\n",
              "  'area': 1666},\n",
              " {'image_id': None,\n",
              "  'bbox': [759, 231, 22, 18],\n",
              "  'score': 0.9921348094940186,\n",
              "  'category_id': 2,\n",
              "  'category_name': 'car',\n",
              "  'segmentation': [],\n",
              "  'iscrowd': 0,\n",
              "  'area': 396}]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.to_coco_annotations()[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m0qwYsi62IP"
      },
      "source": [
        "- ObjectPrediction's can be converted to [COCO prediction](https://github.com/i008/COCO-dataset-explorer) format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAd4LSSD6Zru",
        "outputId": "6febaa22-e18e-4373-b469-a74365523f2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'image_id': 1,\n",
              "  'bbox': [656, 197, 15, 18],\n",
              "  'score': 0.9950496554374695,\n",
              "  'category_id': 2,\n",
              "  'category_name': 'car',\n",
              "  'segmentation': [],\n",
              "  'iscrowd': 0,\n",
              "  'area': 270},\n",
              " {'image_id': 1,\n",
              "  'bbox': [446, 308, 49, 34],\n",
              "  'score': 0.9942396879196167,\n",
              "  'category_id': 2,\n",
              "  'category_name': 'car',\n",
              "  'segmentation': [],\n",
              "  'iscrowd': 0,\n",
              "  'area': 1666},\n",
              " {'image_id': 1,\n",
              "  'bbox': [759, 231, 22, 18],\n",
              "  'score': 0.9921349287033081,\n",
              "  'category_id': 2,\n",
              "  'category_name': 'car',\n",
              "  'segmentation': [],\n",
              "  'iscrowd': 0,\n",
              "  'area': 396}]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.to_coco_predictions(image_id=1)[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGb-9dXI67HQ"
      },
      "source": [
        "- ObjectPrediction's can be converted to [imantics](https://github.com/jsbroks/imantics) annotation format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQ7JQ4bgoYNl"
      },
      "outputs": [],
      "source": [
        "!pip install -U imantics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTlV67X9Zj45",
        "outputId": "e0374f79-7767-4a7c-fc5a-6e7dca56d220"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<imantics.annotation.Annotation at 0x7fce3bab95e0>,\n",
              " <imantics.annotation.Annotation at 0x7fce30371880>,\n",
              " <imantics.annotation.Annotation at 0x7fce30371f40>]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.to_imantics_annotations()[:3]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Detectron2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('sahi')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2680c47b11e1b3873482f0b7ab37c9292181f84f7b4413a77eb41d52d22c05d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
