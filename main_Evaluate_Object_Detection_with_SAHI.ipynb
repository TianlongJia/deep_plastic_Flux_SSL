{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W65GPvi1XDsl"
      },
      "source": [
        "# Oject detection evaluation with SAHI\n",
        "\n",
        "Test a Detector on A Customized Dataset (here, I use the Faster RCNN)\n",
        "\n",
        "https://github.com/obss/sahi\n",
        "\n",
        "https://medium.com/voxel51/how-to-detect-small-objects-cfa569b4d5bd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCl2HeNi0wfY"
      },
      "source": [
        "- Import required modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "\n",
        "from sahi.utils.detectron2 import Detectron2TestConstants\n",
        "\n",
        "# import required functions, classes\n",
        "from sahi import AutoDetectionModel\n",
        "from sahi.predict import get_sliced_prediction, predict, get_prediction\n",
        "from sahi.utils.file import download_from_url\n",
        "from sahi.utils.cv import read_image\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the custom model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # SSL_100per\n",
        "# model_checkpoint_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/RN50_500K/Exp1/RN50_500K_200e/SSL_100per_1/model_best_83.6285.pth\"\n",
        "# model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/RN50_500K/Exp1/RN50_500K_200e/SSL_100per_1/config.yaml\"\n",
        "\n",
        "# # SSL_60per\n",
        "# model_checkpoint_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/RN50_500K/Exp1/RN50_500K_200e/SSL_60per_1/model_best_83.5254.pth\"\n",
        "# model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/RN50_500K/Exp1/RN50_500K_200e/SSL_60per_1/config.yaml\"\n",
        "\n",
        "# # SSL_20per\n",
        "# model_checkpoint_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/RN50_500K/Exp1/RN50_500K_200e/SSL_20per_1/model_best_75.8320.pth\"\n",
        "# model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/RN50_500K/Exp1/RN50_500K_200e/SSL_20per_1/config.yaml\"\n",
        "\n",
        "# SSL_20per_7\n",
        "model_checkpoint_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/RN50_500K/Exp1/RN50_500K_200e/SSL_20per_7/model_best_80.2237.pth\"\n",
        "model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/RN50_500K/Exp1/RN50_500K_200e/SSL_20per_7/config.yaml\"\n",
        "\n",
        "\n",
        "# BL_100per\n",
        "# model_checkpoint_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/SL_100per_1/model_best_77.7978.pth\"\n",
        "# model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/SL_100per_1/config.yaml\"\n",
        "\n",
        "# # BL_60per\n",
        "# model_checkpoint_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/SL_60per_1/model_best_74.6865.pth\"\n",
        "# model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/SL_60per_1/config.yaml\"\n",
        "\n",
        "# # # BL_20per\n",
        "# model_checkpoint_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/SL_20per_1/model_best_69.3043.pth\"\n",
        "# model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/SL_20per_1/config.yaml\"\n",
        "\n",
        "\n",
        "############# Few shot  ###########\n",
        "\n",
        "# SSL_100per_1 is fine-tuned on 0609\n",
        "# model_checkpoint_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/RN50_500K/Exp2/Few_shot_0609_F0_SSL_100per/model_best_76.1218.pth\"\n",
        "# model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/RN50_500K/Exp2/Few_shot_0609_F0_SSL_100per/config.yaml\"\n",
        "\n",
        "\n",
        "# BL_100per_1 is fine-tuned on 0609\n",
        "# model_checkpoint_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/Exp2/Few_shot_0609_F0_SL_100per/model_best_86.4369.pth\"\n",
        "# model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/Exp2/Few_shot_0609_F0_SL_100per/config.yaml\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register my custom train and test dataset\n",
        "\n",
        "dataset should be in COCO format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Register a test dataset\n",
        "\n",
        "# # Flux_train_100per\n",
        "# register_coco_instances(\"Flux_train_100per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Train_100per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Train_100per/\")\n",
        "# register_coco_instances(\"Flux_val_100per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Val_100per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Val_100per/\")\n",
        "# Train_Dataset_name=\"Flux_train_100per\"\n",
        "# Test_Dataset_name=\"Flux_val_100per\"\n",
        "# Class_name=[\"litter\"]\n",
        "\n",
        "# # # Flux_train_60per\n",
        "# register_coco_instances(\"Flux_train_60per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Train_60per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Train_60per/\")\n",
        "# register_coco_instances(\"Flux_val_60per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Val_60per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Val_60per/\")\n",
        "# Train_Dataset_name=\"Flux_train_60per\"\n",
        "# Test_Dataset_name=\"Flux_val_60per\"\n",
        "# Class_name=[\"litter\"]\n",
        "\n",
        "# Flux_train_20per\n",
        "register_coco_instances(\"Flux_train_20per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Train_20per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Train_20per/\")\n",
        "register_coco_instances(\"Flux_val_20per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Val_20per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Val_20per/\")\n",
        "Train_Dataset_name=\"Flux_train_20per\"\n",
        "Test_Dataset_name=\"Flux_val_20per\"\n",
        "Class_name=[\"litter\"]\n",
        "\n",
        "############# Few shot  ###########\n",
        "# # fine-tune on 0609\n",
        "# register_coco_instances(\"FS_train_0609\", {}, \"/scratch/tjian/Data/Flux/TUD_Vietnam/0609/Fine_tune/annotations/train.json\", \"/scratch/tjian/Data/Flux/TUD_Vietnam/0609/Fine_tune/train/\")\n",
        "# register_coco_instances(\"FS_val_0609\", {}, \"/scratch/tjian/Data/Flux/TUD_Vietnam/0609/Fine_tune/annotations/val.json\", \"/scratch/tjian/Data/Flux/TUD_Vietnam/0609/Fine_tune/val/\")\n",
        "# Train_Dataset_name=\"FS_train_0609\"\n",
        "# Test_Dataset_name=\"FS_val_0609\"\n",
        "# Class_name=[\"litter\"]\n",
        "\n",
        "MetadataCatalog.get(Train_Dataset_name).set(thing_classes=Class_name)\n",
        "MetadataCatalog.get(Test_Dataset_name).set(thing_classes=Class_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build a detection model\n",
        "\n",
        "Instantiate a detection model by defining model weight path, confing path and other parameters.\n",
        "\n",
        "This model will be used to inference in slicing images or original images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \"image_size\": Input image size for each inference (image is scaled by preserving aspect ratio).\n",
        "# there is no default \"image_size\". \n",
        "# So if not set \"image_size\", the image will be resized by the setting in the model config file\n",
        "\n",
        "# \"device\": (1) \"cpu\", or (2) 'cuda:0'\n",
        "\n",
        "detection_model = AutoDetectionModel.from_pretrained(\n",
        "    model_type='detectron2',\n",
        "    model_path=model_checkpoint_path,\n",
        "    config_path=model_config_path,\n",
        "    confidence_threshold=0.9,\n",
        "    # image_size=1333,\n",
        "    device=\"cuda:0\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1 Predict an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define image path\n",
        "image_path=r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0609/images_with_litter/BL_2023_09_06_Sweep_1_5_DCSS0262.jpg\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.1 Standard Inference with a Detectron2 Model\n",
        "\n",
        "- Perform prediction by feeding the get_prediction function with an image path and a DetectionModel instance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "export_dir=r\"/scratch/tjian/Data/Flux/TUD_Vietnam/test/\"\n",
        "output_file_name=\"BL_2023_09_06_Sweep_1_5_DCSS0262\"   # do not end with \"\".jpg\n",
        "\n",
        "result = get_prediction(image_path, detection_model)\n",
        "result.export_visuals(export_dir, \n",
        "                      text_size=3, # float\n",
        "                      file_name=output_file_name)\n",
        "\n",
        "# output No. detections\n",
        "num_orig_dets = len(result.to_fiftyone_detections())\n",
        "print(f\"Detections predicted without slicing: {num_orig_dets}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9Y2kCRz6Y74"
      },
      "source": [
        "#### 1.2 Sliced Inference with a Detectron2 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPsuXa_R6gKl"
      },
      "source": [
        "- To perform sliced prediction we need to specify slice parameters. In this example we will perform prediction over slices of slice_width*slice_height (e.g.,256x256) with an overlap ratio of 0.2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM6uCgAS6Ze4",
        "outputId": "a703b758-0141-4ac7-f7b2-0804f7b10070"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing prediction on 15 number of slices.\n"
          ]
        }
      ],
      "source": [
        "export_dir=r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0609/Predict/R50_300K_100e/SAHI/test/\"\n",
        "output_file_name= \"BL_2023_09_06_Sweep_1_5_DCSS0262\"   # do not end with \"\".jpg\n",
        "\n",
        "result = get_sliced_prediction(\n",
        "    image_path,\n",
        "    detection_model,\n",
        "    slice_height = 640,\n",
        "    slice_width = 640,\n",
        "    overlap_height_ratio = 0.2,\n",
        "    overlap_width_ratio = 0.2,\n",
        ")\n",
        "\n",
        "result.export_visuals(export_dir, \n",
        "                      text_size=3,\n",
        "                      file_name=output_file_name)\n",
        "\n",
        "# output No. detections\n",
        "num_sliced_dets = len(result.to_fiftyone_detections())\n",
        "print(f\"Detections predicted with slicing: {num_sliced_dets}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2 Predict images in a folder (Sliced Inference)\n",
        "\n",
        "Output:\n",
        "\n",
        "(1) predicted images (the code will save the predicted images in a subfolder named *\"pred_images\"*); \n",
        "\n",
        "(2) A excel file named *\"detection_results.xlsx\"*, stores filename and No.detections\n",
        "\n",
        "(3) Print the total number of detections in the console\n",
        "\n",
        "\"postprocess_type\": Options are 'NMM', 'GREEDYNMM', 'LSNMS' or 'NMS'. Default is 'GREEDYNMM'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# source_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/images_no_litter/\"  # 0909\n",
        "source_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/images_no_litter/\"  # 1209\n",
        "# source_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/all_images/\"  # all\n",
        "\n",
        "\n",
        "# do not generate the output_dir, the code will do it automatically\n",
        "# output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/Pred/SSL_20per_7/SA_1280_Conf_0.5/No_litter\"  # 0909\n",
        "output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/Pred/SSL_20per_7/SA_1920_Conf_0.9/No_litter\"  # 1209\n",
        "# output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/BL_Pred_All/SAHF_1280_Conf_0.9/\"   # all\n",
        "\n",
        "# define slicing conf.\n",
        "slice_height = 1920\n",
        "slice_width = 1920\n",
        "overlap_height_ratio = 0.2\n",
        "overlap_width_ratio = 0.2\n",
        "\n",
        "# Perform sliced inference on given folder\n",
        "# it will also output the (total) number of detections in each/all images\n",
        "result = predict(\n",
        "    detection_model = detection_model,\n",
        "    source = source_image_dir,\n",
        "    slice_height = slice_height,\n",
        "    slice_width = slice_width,\n",
        "    overlap_height_ratio = overlap_height_ratio,\n",
        "    overlap_width_ratio = overlap_width_ratio,\n",
        "    project = output_dir,\n",
        "    postprocess_type = 'NMS', # dDefault is 'GREEDYNMM'.\n",
        "    postprocess_match_metric = 'IOU',\n",
        "    postprocess_match_threshold = 0.5, # NMS_IoU_threshold\n",
        "    visual_text_size = 3 # float\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3 Evaluate in a labeled dataset\n",
        "\n",
        "In the output path, the code generates:ã€€\n",
        "\n",
        "(1) predicted images (the code will save the predicted images in a subfolder named *\"pred_images\"*); \n",
        "\n",
        "(2) a subfolder named *\"visuals_with_gt\"* including images with ground-truth and predictions;\n",
        "\n",
        "(3) a json file \"results.json\" including prediction results;\n",
        "\n",
        "(4) A excel file named *\"detection_results.xlsx\"*, stores filename and No.detections\n",
        "\n",
        "(5) Print the total number of detections in the console"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1 Processing images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/images_with_litter/\"\n",
        "test_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/images_with_litter/\"\n",
        "\n",
        "# test dataset (with annotations)\n",
        "# test_annotation_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/annotations/0909.json\"\n",
        "test_annotation_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/annotations/1209.json\"\n",
        "\n",
        "\n",
        "# do not generate the output_dir, the code will do it automatically\n",
        "# output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/Pred/SSL_20per_7/SA_1280_Conf_0.5/With_litter\"\n",
        "output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/Pred/SSL_20per_7/SA_1920_Conf_0.9/With_litter\"\n",
        "\n",
        "# define slicing conf.\n",
        "slice_height = 1920\n",
        "slice_width = 1920\n",
        "overlap_height_ratio = 0.2\n",
        "overlap_width_ratio = 0.2\n",
        "\n",
        "# Perform sliced inference on given folder:\n",
        "# it will also output the (total) number of detections in each/all images\n",
        "predict(\n",
        "    detection_model = detection_model,\n",
        "    source = test_image_dir,\n",
        "    slice_height = slice_height,\n",
        "    slice_width = slice_width,\n",
        "    overlap_height_ratio = overlap_height_ratio,\n",
        "    overlap_width_ratio = overlap_width_ratio,\n",
        "    project = output_dir,\n",
        "    dataset_json_path = test_annotation_path,\n",
        "    postprocess_type = 'NMS', # dDefault is 'GREEDYNMM'.\n",
        "    postprocess_match_metric = 'IOU',\n",
        "    postprocess_match_threshold = 0.5, # NMS_IoU_threshold\n",
        "    visual_text_size = 3 # float\n",
        "    # visual_bbox_thickness = None  # init\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.2 Modify the output json file\n",
        "\n",
        "Note: the \"results.json\" file output in the above code (1) has an issue of category. \n",
        "\n",
        "By default, Detectron2 or SAHI starts the category_id from \"0\". But the category_id starts from \"1\" in my input annotation file. \n",
        "\n",
        "Thus, it is **necessary** that all category IDs are incremented by 1 in the output json file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "input_json = r'/scratch/tjian/Data/Flux/TUD_Vietnam/1209/Pred/SL_100per/SA_1280_Conf_0.9/With_litter/results.json'\n",
        "output_json = r'/scratch/tjian/Data/Flux/TUD_Vietnam/1209/Pred/SL_100per/SA_1280_Conf_0.9/With_litter/results_new.json'\n",
        "\n",
        "# Read the JSON file\n",
        "with open(input_json, 'r') as file:\n",
        "    coco_data = json.load(file)\n",
        "\n",
        "# Check if the JSON structure is a list or a dictionary\n",
        "if isinstance(coco_data, list):\n",
        "    # Assume the list contains annotation dictionaries directly\n",
        "    for annotation in coco_data:\n",
        "        annotation['category_id'] += 1\n",
        "else:\n",
        "    # Assume it's a dictionary with an 'annotations' key\n",
        "    for annotation in coco_data.get('annotations', []):\n",
        "        annotation['category_id'] += 1\n",
        "\n",
        "# Save the modified JSON to a new file\n",
        "with open(output_json, 'w') as file:\n",
        "    json.dump(coco_data, file, indent=4)\n",
        "\n",
        "print(f\"All category IDs have been incremented by 1 and saved to {output_json}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.3 Output evaulation metrics in \"main_Confusion_matrix_OD.ipynb\"\n",
        "\n",
        "e.g., mAP, TP, FP, FN, precision, recall, F1-score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwn78AeP6rVK"
      },
      "source": [
        "### 3. To do: Prediction Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BG-je0V6uCn"
      },
      "source": [
        "- Predictions are returned as [sahi.prediction.PredictionResult](sahi/prediction.py), you can access the object prediction list as:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10 runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "\n",
        "from sahi.utils.detectron2 import Detectron2TestConstants\n",
        "\n",
        "# import required functions, classes\n",
        "from sahi import AutoDetectionModel\n",
        "from sahi.predict import get_sliced_prediction, predict, get_prediction\n",
        "from sahi.utils.file import download_from_url\n",
        "from sahi.utils.cv import read_image\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SL_100per on 0909 with litter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "files_path = r\"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/100per_10_runs/\"\n",
        "files = os.listdir(files_path)\n",
        "model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/SL_100per_1/config.yaml\"\n",
        "\n",
        "test_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/images_with_litter/\"\n",
        "# test_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/images_with_litter/\"\n",
        "\n",
        "# test dataset (with annotations)\n",
        "test_annotation_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/annotations/0909.json\"\n",
        "# test_annotation_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/annotations/1209.json\"\n",
        "\n",
        "ori_output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/Pred/SL_100per/SA_1280_Conf_0.9/With_litter\"\n",
        "\n",
        "# # Flux_train_100per\n",
        "register_coco_instances(\"Flux_train_100per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Train_100per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Train_100per/\")\n",
        "register_coco_instances(\"Flux_val_100per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Val_100per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Val_100per/\")\n",
        "Train_Dataset_name=\"Flux_train_100per\"\n",
        "Test_Dataset_name=\"Flux_val_100per\"\n",
        "Class_name=[\"litter\"]\n",
        "MetadataCatalog.get(Train_Dataset_name).set(thing_classes=Class_name)\n",
        "MetadataCatalog.get(Test_Dataset_name).set(thing_classes=Class_name)\n",
        "\n",
        "\n",
        "for filename in files:\n",
        "    print(\"#################\", filename, \"################\")\n",
        "    head, sep, tail = filename.partition('.pth')\n",
        "    if str(sep) == '.pth':\n",
        "      new_folder_name = head  # build the new name\n",
        "    model_checkpoint_path = os.path.join(files_path, filename)\n",
        "    detection_model = AutoDetectionModel.from_pretrained(\n",
        "      model_type='detectron2',\n",
        "      model_path=model_checkpoint_path,\n",
        "      config_path=model_config_path,\n",
        "      confidence_threshold=0.9,\n",
        "      # image_size=1333,\n",
        "      device=\"cuda:0\",\n",
        "      )\n",
        "    # do not generate the output_dir, the code will do it automatically\n",
        "    output_dir = os.path.join(ori_output_dir, new_folder_name)\n",
        "    # define slicing conf.\n",
        "    slice_height = 1280\n",
        "    slice_width = 1280\n",
        "    overlap_height_ratio = 0.2\n",
        "    overlap_width_ratio = 0.2\n",
        "    predict(\n",
        "      detection_model = detection_model,\n",
        "      source = test_image_dir,\n",
        "      slice_height = slice_height,\n",
        "      slice_width = slice_width,\n",
        "      overlap_height_ratio = overlap_height_ratio,\n",
        "      overlap_width_ratio = overlap_width_ratio,\n",
        "      project = output_dir,\n",
        "      dataset_json_path = test_annotation_path,\n",
        "      postprocess_type = 'NMS', # dDefault is 'GREEDYNMM'.\n",
        "      postprocess_match_metric = 'IOU',\n",
        "      postprocess_match_threshold = 0.5, # NMS_IoU_threshold\n",
        "      visual_text_size = 3 # float\n",
        "      # visual_bbox_thickness = None  # init\n",
        "      )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SL_100per on 0909 with no litter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "files_path = r\"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/100per_10_runs/\"\n",
        "files = os.listdir(files_path)\n",
        "model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/SL_100per_1/config.yaml\"\n",
        "\n",
        "source_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/images_no_litter/\"  # 0909\n",
        "# source_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/images_no_litter/\"  # 1209\n",
        "\n",
        "ori_output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/Pred/SL_100per/SA_1280_Conf_0.9/No_litter\"  # 0909\n",
        "# ori_output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/Pred/SSL_20per/SA_1920_Conf_0.9/No_litter\"  # 1209\n",
        "\n",
        "# # Flux_train_100per\n",
        "register_coco_instances(\"Flux_train_100per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Train_100per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Train_100per/\")\n",
        "register_coco_instances(\"Flux_val_100per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Val_100per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Val_100per/\")\n",
        "Train_Dataset_name=\"Flux_train_100per\"\n",
        "Test_Dataset_name=\"Flux_val_100per\"\n",
        "Class_name=[\"litter\"]\n",
        "MetadataCatalog.get(Train_Dataset_name).set(thing_classes=Class_name)\n",
        "MetadataCatalog.get(Test_Dataset_name).set(thing_classes=Class_name)\n",
        "\n",
        "for filename in files:\n",
        "    print(\"#################\", filename, \"################\")\n",
        "    head, sep, tail = filename.partition('.pth')\n",
        "    if str(sep) == '.pth':\n",
        "      new_folder_name = head  # build the new name\n",
        "    model_checkpoint_path = os.path.join(files_path, filename)\n",
        "    detection_model = AutoDetectionModel.from_pretrained(\n",
        "      model_type='detectron2',\n",
        "      model_path=model_checkpoint_path,\n",
        "      config_path=model_config_path,\n",
        "      confidence_threshold=0.9,\n",
        "      # image_size=1333,\n",
        "      device=\"cuda:0\",\n",
        "      )\n",
        "    # do not generate the output_dir, the code will do it automatically\n",
        "    output_dir = os.path.join(ori_output_dir, new_folder_name)\n",
        "    # define slicing conf.\n",
        "    slice_height = 1280\n",
        "    slice_width = 1280\n",
        "    overlap_height_ratio = 0.2\n",
        "    overlap_width_ratio = 0.2\n",
        "    result = predict(\n",
        "      detection_model = detection_model,\n",
        "      source = source_image_dir,\n",
        "      slice_height = slice_height,\n",
        "      slice_width = slice_width,\n",
        "      overlap_height_ratio = overlap_height_ratio,\n",
        "      overlap_width_ratio = overlap_width_ratio,\n",
        "      project = output_dir,\n",
        "      postprocess_type = 'NMS', # dDefault is 'GREEDYNMM'.\n",
        "      postprocess_match_metric = 'IOU',\n",
        "      postprocess_match_threshold = 0.5, # NMS_IoU_threshold\n",
        "      visual_text_size = 3 # float\n",
        "      )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SL_60per on 0909 with litter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "files_path = r\"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/60per_10_runs/\"\n",
        "files = os.listdir(files_path)\n",
        "model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/SL_60per_1/config.yaml\"\n",
        "\n",
        "test_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/images_with_litter/\"\n",
        "# test_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/images_with_litter/\"\n",
        "\n",
        "# test dataset (with annotations)\n",
        "test_annotation_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/annotations/0909.json\"\n",
        "# test_annotation_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/annotations/1209.json\"\n",
        "\n",
        "ori_output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/Pred/SL_60per/SA_1280_Conf_0.9/With_litter\"\n",
        "\n",
        "# # # Flux_train_60per\n",
        "register_coco_instances(\"Flux_train_60per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Train_60per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Train_60per/\")\n",
        "register_coco_instances(\"Flux_val_60per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Val_60per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Val_60per/\")\n",
        "Train_Dataset_name=\"Flux_train_60per\"\n",
        "Test_Dataset_name=\"Flux_val_60per\"\n",
        "Class_name=[\"litter\"]\n",
        "MetadataCatalog.get(Train_Dataset_name).set(thing_classes=Class_name)\n",
        "MetadataCatalog.get(Test_Dataset_name).set(thing_classes=Class_name)\n",
        "\n",
        "\n",
        "for filename in files:\n",
        "    print(\"#################\", filename, \"################\")\n",
        "    head, sep, tail = filename.partition('.pth')\n",
        "    if str(sep) == '.pth':\n",
        "      new_folder_name = head  # build the new name\n",
        "    model_checkpoint_path = os.path.join(files_path, filename)\n",
        "    detection_model = AutoDetectionModel.from_pretrained(\n",
        "      model_type='detectron2',\n",
        "      model_path=model_checkpoint_path,\n",
        "      config_path=model_config_path,\n",
        "      confidence_threshold=0.9,\n",
        "      # image_size=1333,\n",
        "      device=\"cuda:0\",\n",
        "      )\n",
        "    # do not generate the output_dir, the code will do it automatically\n",
        "    output_dir = os.path.join(ori_output_dir, new_folder_name)\n",
        "    # define slicing conf.\n",
        "    slice_height = 1280\n",
        "    slice_width = 1280\n",
        "    overlap_height_ratio = 0.2\n",
        "    overlap_width_ratio = 0.2\n",
        "    predict(\n",
        "      detection_model = detection_model,\n",
        "      source = test_image_dir,\n",
        "      slice_height = slice_height,\n",
        "      slice_width = slice_width,\n",
        "      overlap_height_ratio = overlap_height_ratio,\n",
        "      overlap_width_ratio = overlap_width_ratio,\n",
        "      project = output_dir,\n",
        "      dataset_json_path = test_annotation_path,\n",
        "      postprocess_type = 'NMS', # dDefault is 'GREEDYNMM'.\n",
        "      postprocess_match_metric = 'IOU',\n",
        "      postprocess_match_threshold = 0.5, # NMS_IoU_threshold\n",
        "      visual_text_size = 3 # float\n",
        "      # visual_bbox_thickness = None  # init\n",
        "      )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SL_60per on 0909 with no litter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "files_path = r\"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/60per_10_runs/\"\n",
        "files = os.listdir(files_path)\n",
        "model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/SL_60per_1/config.yaml\"\n",
        "\n",
        "source_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/images_no_litter/\"  # 0909\n",
        "# source_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/images_no_litter/\"  # 1209\n",
        "\n",
        "ori_output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/Pred/SL_60per/SA_1280_Conf_0.9/No_litter\"  # 0909\n",
        "# ori_output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/Pred/SSL_20per/SA_1920_Conf_0.9/No_litter\"  # 1209\n",
        "\n",
        "# # Flux_train_60per\n",
        "register_coco_instances(\"Flux_train_60per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Train_60per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Train_60per/\")\n",
        "register_coco_instances(\"Flux_val_60per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Val_60per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Val_60per/\")\n",
        "Train_Dataset_name=\"Flux_train_60per\"\n",
        "Test_Dataset_name=\"Flux_val_60per\"\n",
        "Class_name=[\"litter\"]\n",
        "MetadataCatalog.get(Train_Dataset_name).set(thing_classes=Class_name)\n",
        "MetadataCatalog.get(Test_Dataset_name).set(thing_classes=Class_name)\n",
        "\n",
        "for filename in files:\n",
        "    print(\"#################\", filename, \"################\")\n",
        "    head, sep, tail = filename.partition('.pth')\n",
        "    if str(sep) == '.pth':\n",
        "      new_folder_name = head  # build the new name\n",
        "    model_checkpoint_path = os.path.join(files_path, filename)\n",
        "    detection_model = AutoDetectionModel.from_pretrained(\n",
        "      model_type='detectron2',\n",
        "      model_path=model_checkpoint_path,\n",
        "      config_path=model_config_path,\n",
        "      confidence_threshold=0.9,\n",
        "      # image_size=1333,\n",
        "      device=\"cuda:0\",\n",
        "      )\n",
        "    # do not generate the output_dir, the code will do it automatically\n",
        "    output_dir = os.path.join(ori_output_dir, new_folder_name)\n",
        "    # define slicing conf.\n",
        "    slice_height = 1280\n",
        "    slice_width = 1280\n",
        "    overlap_height_ratio = 0.2\n",
        "    overlap_width_ratio = 0.2\n",
        "    result = predict(\n",
        "      detection_model = detection_model,\n",
        "      source = source_image_dir,\n",
        "      slice_height = slice_height,\n",
        "      slice_width = slice_width,\n",
        "      overlap_height_ratio = overlap_height_ratio,\n",
        "      overlap_width_ratio = overlap_width_ratio,\n",
        "      project = output_dir,\n",
        "      postprocess_type = 'NMS', # dDefault is 'GREEDYNMM'.\n",
        "      postprocess_match_metric = 'IOU',\n",
        "      postprocess_match_threshold = 0.5, # NMS_IoU_threshold\n",
        "      visual_text_size = 3 # float\n",
        "      )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SL_20per on 0909 with litter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "files_path = r\"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/20per_10_runs/\"\n",
        "files = os.listdir(files_path)\n",
        "model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/SL_20per_1/config.yaml\"\n",
        "\n",
        "test_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/images_with_litter/\"\n",
        "# test_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/images_with_litter/\"\n",
        "\n",
        "# test dataset (with annotations)\n",
        "test_annotation_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/annotations/0909.json\"\n",
        "# test_annotation_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/annotations/1209.json\"\n",
        "\n",
        "ori_output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/Pred/SL_20per/SA_1280_Conf_0.9/With_litter\"\n",
        "\n",
        "# Flux_train_20per\n",
        "register_coco_instances(\"Flux_train_20per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Train_20per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Train_20per/\")\n",
        "register_coco_instances(\"Flux_val_20per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Val_20per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Val_20per/\")\n",
        "Train_Dataset_name=\"Flux_train_20per\"\n",
        "Test_Dataset_name=\"Flux_val_20per\"\n",
        "Class_name=[\"litter\"]\n",
        "MetadataCatalog.get(Train_Dataset_name).set(thing_classes=Class_name)\n",
        "MetadataCatalog.get(Test_Dataset_name).set(thing_classes=Class_name)\n",
        "\n",
        "\n",
        "for filename in files:\n",
        "    print(\"#################\", filename, \"################\")\n",
        "    head, sep, tail = filename.partition('.pth')\n",
        "    if str(sep) == '.pth':\n",
        "      new_folder_name = head  # build the new name\n",
        "    model_checkpoint_path = os.path.join(files_path, filename)\n",
        "    detection_model = AutoDetectionModel.from_pretrained(\n",
        "      model_type='detectron2',\n",
        "      model_path=model_checkpoint_path,\n",
        "      config_path=model_config_path,\n",
        "      confidence_threshold=0.9,\n",
        "      # image_size=1333,\n",
        "      device=\"cuda:0\",\n",
        "      )\n",
        "    # do not generate the output_dir, the code will do it automatically\n",
        "    output_dir = os.path.join(ori_output_dir, new_folder_name)\n",
        "    # define slicing conf.\n",
        "    slice_height = 1280\n",
        "    slice_width = 1280\n",
        "    overlap_height_ratio = 0.2\n",
        "    overlap_width_ratio = 0.2\n",
        "    predict(\n",
        "      detection_model = detection_model,\n",
        "      source = test_image_dir,\n",
        "      slice_height = slice_height,\n",
        "      slice_width = slice_width,\n",
        "      overlap_height_ratio = overlap_height_ratio,\n",
        "      overlap_width_ratio = overlap_width_ratio,\n",
        "      project = output_dir,\n",
        "      dataset_json_path = test_annotation_path,\n",
        "      postprocess_type = 'NMS', # dDefault is 'GREEDYNMM'.\n",
        "      postprocess_match_metric = 'IOU',\n",
        "      postprocess_match_threshold = 0.5, # NMS_IoU_threshold\n",
        "      visual_text_size = 3 # float\n",
        "      # visual_bbox_thickness = None  # init\n",
        "      )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SL_20per on 0909 with no litter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "files_path = r\"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/20per_10_runs/\"\n",
        "files = os.listdir(files_path)\n",
        "model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/SL_20per_1/config.yaml\"\n",
        "\n",
        "source_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/images_no_litter/\"  # 0909\n",
        "# source_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/images_no_litter/\"  # 1209\n",
        "\n",
        "ori_output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/0909/Pred/SL_20per/SA_1280_Conf_0.9/No_litter\"  # 0909\n",
        "# ori_output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/Pred/SSL_20per/SA_1920_Conf_0.9/No_litter\"  # 1209\n",
        "\n",
        "# # Flux_train_20per\n",
        "register_coco_instances(\"Flux_train_20per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Train_20per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Train_20per/\")\n",
        "register_coco_instances(\"Flux_val_20per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Val_20per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Val_20per/\")\n",
        "Train_Dataset_name=\"Flux_train_20per\"\n",
        "Test_Dataset_name=\"Flux_val_20per\"\n",
        "Class_name=[\"litter\"]\n",
        "MetadataCatalog.get(Train_Dataset_name).set(thing_classes=Class_name)\n",
        "MetadataCatalog.get(Test_Dataset_name).set(thing_classes=Class_name)\n",
        "\n",
        "for filename in files:\n",
        "    print(\"#################\", filename, \"################\")\n",
        "    head, sep, tail = filename.partition('.pth')\n",
        "    if str(sep) == '.pth':\n",
        "      new_folder_name = head  # build the new name\n",
        "    model_checkpoint_path = os.path.join(files_path, filename)\n",
        "    detection_model = AutoDetectionModel.from_pretrained(\n",
        "      model_type='detectron2',\n",
        "      model_path=model_checkpoint_path,\n",
        "      config_path=model_config_path,\n",
        "      confidence_threshold=0.9,\n",
        "      # image_size=1333,\n",
        "      device=\"cuda:0\",\n",
        "      )\n",
        "    # do not generate the output_dir, the code will do it automatically\n",
        "    output_dir = os.path.join(ori_output_dir, new_folder_name)\n",
        "    # define slicing conf.\n",
        "    slice_height = 1280\n",
        "    slice_width = 1280\n",
        "    overlap_height_ratio = 0.2\n",
        "    overlap_width_ratio = 0.2\n",
        "    result = predict(\n",
        "      detection_model = detection_model,\n",
        "      source = source_image_dir,\n",
        "      slice_height = slice_height,\n",
        "      slice_width = slice_width,\n",
        "      overlap_height_ratio = overlap_height_ratio,\n",
        "      overlap_width_ratio = overlap_width_ratio,\n",
        "      project = output_dir,\n",
        "      postprocess_type = 'NMS', # dDefault is 'GREEDYNMM'.\n",
        "      postprocess_match_metric = 'IOU',\n",
        "      postprocess_match_threshold = 0.5, # NMS_IoU_threshold\n",
        "      visual_text_size = 3 # float\n",
        "      )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SL_100per on 1209 with litter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "files_path = r\"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/100per_10_runs/\"\n",
        "files = os.listdir(files_path)\n",
        "model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/SL_100per_1/config.yaml\"\n",
        "\n",
        "test_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/images_with_litter/\"\n",
        "\n",
        "# test dataset (with annotations)\n",
        "test_annotation_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/annotations/1209.json\"\n",
        "\n",
        "ori_output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/Pred/SL_100per/SA_1920_Conf_0.9/With_litter\"\n",
        "\n",
        "# # Flux_train_100per\n",
        "register_coco_instances(\"Flux_train_100per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Train_100per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Train_100per/\")\n",
        "register_coco_instances(\"Flux_val_100per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Val_100per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Val_100per/\")\n",
        "Train_Dataset_name=\"Flux_train_100per\"\n",
        "Test_Dataset_name=\"Flux_val_100per\"\n",
        "Class_name=[\"litter\"]\n",
        "MetadataCatalog.get(Train_Dataset_name).set(thing_classes=Class_name)\n",
        "MetadataCatalog.get(Test_Dataset_name).set(thing_classes=Class_name)\n",
        "\n",
        "for filename in files:\n",
        "    print(\"#################\", filename, \"################\")\n",
        "    head, sep, tail = filename.partition('.pth')\n",
        "    if str(sep) == '.pth':\n",
        "      new_folder_name = head  # build the new name\n",
        "    model_checkpoint_path = os.path.join(files_path, filename)\n",
        "    detection_model = AutoDetectionModel.from_pretrained(\n",
        "        model_type='detectron2',\n",
        "        model_path=model_checkpoint_path,\n",
        "        config_path=model_config_path,\n",
        "        confidence_threshold=0.9,\n",
        "        # image_size=1333,\n",
        "        device=\"cuda:0\",\n",
        "        )\n",
        "    # do not generate the output_dir, the code will do it automatically\n",
        "    output_dir = os.path.join(ori_output_dir, new_folder_name)\n",
        "    # define slicing conf.\n",
        "    slice_height = 1920\n",
        "    slice_width = 1920\n",
        "    overlap_height_ratio = 0.2\n",
        "    overlap_width_ratio = 0.2\n",
        "    predict(\n",
        "        detection_model = detection_model,\n",
        "        source = test_image_dir,\n",
        "        slice_height = slice_height,\n",
        "        slice_width = slice_width,\n",
        "        overlap_height_ratio = overlap_height_ratio,\n",
        "        overlap_width_ratio = overlap_width_ratio,\n",
        "        project = output_dir,\n",
        "        dataset_json_path = test_annotation_path,\n",
        "        postprocess_type = 'NMS', # dDefault is 'GREEDYNMM'.\n",
        "        postprocess_match_metric = 'IOU',\n",
        "        postprocess_match_threshold = 0.5, # NMS_IoU_threshold\n",
        "        visual_text_size = 3 # float\n",
        "        # visual_bbox_thickness = None  # init\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SL_100per on 1209 with no litter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "files_path = r\"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/100per_10_runs/\"\n",
        "files = os.listdir(files_path)\n",
        "model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/SL_100per_1/config.yaml\"\n",
        "\n",
        "source_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/images_no_litter/\"  # 1209\n",
        "\n",
        "ori_output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/Pred/SL_100per/SA_1920_Conf_0.9/No_litter\"  # 1209\n",
        "\n",
        "# # Flux_train_100per\n",
        "register_coco_instances(\"Flux_train_100per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Train_100per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Train_100per/\")\n",
        "register_coco_instances(\"Flux_val_100per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Val_100per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Val_100per/\")\n",
        "Train_Dataset_name=\"Flux_train_100per\"\n",
        "Test_Dataset_name=\"Flux_val_100per\"\n",
        "Class_name=[\"litter\"]\n",
        "MetadataCatalog.get(Train_Dataset_name).set(thing_classes=Class_name)\n",
        "MetadataCatalog.get(Test_Dataset_name).set(thing_classes=Class_name)\n",
        "\n",
        "for filename in files:\n",
        "    print(\"#################\", filename, \"################\")\n",
        "    head, sep, tail = filename.partition('.pth')\n",
        "    if str(sep) == '.pth':\n",
        "        new_folder_name = head  # build the new name\n",
        "    model_checkpoint_path = os.path.join(files_path, filename)\n",
        "    detection_model = AutoDetectionModel.from_pretrained(\n",
        "          model_type='detectron2',\n",
        "          model_path=model_checkpoint_path,\n",
        "          config_path=model_config_path,\n",
        "          confidence_threshold=0.9,\n",
        "          # image_size=1333,\n",
        "          device=\"cuda:0\",\n",
        "          )\n",
        "    # do not generate the output_dir, the code will do it automatically\n",
        "    output_dir = os.path.join(ori_output_dir, new_folder_name)\n",
        "    # define slicing conf.\n",
        "    slice_height = 1920\n",
        "    slice_width = 1920\n",
        "    overlap_height_ratio = 0.2\n",
        "    overlap_width_ratio = 0.2\n",
        "    result = predict(\n",
        "        detection_model = detection_model,\n",
        "        source = source_image_dir,\n",
        "        slice_height = slice_height,\n",
        "        slice_width = slice_width,\n",
        "        overlap_height_ratio = overlap_height_ratio,\n",
        "        overlap_width_ratio = overlap_width_ratio,\n",
        "        project = output_dir,\n",
        "        postprocess_type = 'NMS', # dDefault is 'GREEDYNMM'.\n",
        "        postprocess_match_metric = 'IOU',\n",
        "        postprocess_match_threshold = 0.5, # NMS_IoU_threshold\n",
        "        visual_text_size = 3 # float\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SL_60per on 1209 with litter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "files_path = r\"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/60per_10_runs/\"\n",
        "files = os.listdir(files_path)\n",
        "model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/SL_60per_1/config.yaml\"\n",
        "\n",
        "test_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/images_with_litter/\"\n",
        "\n",
        "# test dataset (with annotations)\n",
        "test_annotation_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/annotations/1209.json\"\n",
        "\n",
        "ori_output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/Pred/SL_60per/SA_1920_Conf_0.9/With_litter\"\n",
        "\n",
        "# # # Flux_train_60per\n",
        "register_coco_instances(\"Flux_train_60per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Train_60per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Train_60per/\")\n",
        "register_coco_instances(\"Flux_val_60per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Val_60per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Val_60per/\")\n",
        "Train_Dataset_name=\"Flux_train_60per\"\n",
        "Test_Dataset_name=\"Flux_val_60per\"\n",
        "Class_name=[\"litter\"]\n",
        "MetadataCatalog.get(Train_Dataset_name).set(thing_classes=Class_name)\n",
        "MetadataCatalog.get(Test_Dataset_name).set(thing_classes=Class_name)\n",
        "\n",
        "\n",
        "for filename in files:\n",
        "    print(\"#################\", filename, \"################\")\n",
        "    head, sep, tail = filename.partition('.pth')\n",
        "    if str(sep) == '.pth':\n",
        "        new_folder_name = head  # build the new name\n",
        "    model_checkpoint_path = os.path.join(files_path, filename)\n",
        "    detection_model = AutoDetectionModel.from_pretrained(\n",
        "          model_type='detectron2',\n",
        "          model_path=model_checkpoint_path,\n",
        "          config_path=model_config_path,\n",
        "          confidence_threshold=0.9,\n",
        "          # image_size=1333,\n",
        "          device=\"cuda:0\",\n",
        "          )\n",
        "    # do not generate the output_dir, the code will do it automatically\n",
        "    output_dir = os.path.join(ori_output_dir, new_folder_name)\n",
        "    # define slicing conf.\n",
        "    slice_height = 1920\n",
        "    slice_width = 1920\n",
        "    overlap_height_ratio = 0.2\n",
        "    overlap_width_ratio = 0.2\n",
        "    predict(\n",
        "        detection_model = detection_model,\n",
        "        source = test_image_dir,\n",
        "        slice_height = slice_height,\n",
        "        slice_width = slice_width,\n",
        "        overlap_height_ratio = overlap_height_ratio,\n",
        "        overlap_width_ratio = overlap_width_ratio,\n",
        "        project = output_dir,\n",
        "        dataset_json_path = test_annotation_path,\n",
        "        postprocess_type = 'NMS', # dDefault is 'GREEDYNMM'.\n",
        "        postprocess_match_metric = 'IOU',\n",
        "        postprocess_match_threshold = 0.5, # NMS_IoU_threshold\n",
        "        visual_text_size = 3 # float\n",
        "        # visual_bbox_thickness = None  # init\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SL_60per on 1209 with no litter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "files_path = r\"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/60per_10_runs/\"\n",
        "files = os.listdir(files_path)\n",
        "model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/SL_60per_1/config.yaml\"\n",
        "\n",
        "source_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/images_no_litter/\"  # 1209\n",
        "\n",
        "ori_output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/Pred/SL_60per/SA_1920_Conf_0.9/No_litter\"  # 1209\n",
        "\n",
        "# # # Flux_train_60per\n",
        "register_coco_instances(\"Flux_train_60per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Train_60per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Train_60per/\")\n",
        "register_coco_instances(\"Flux_val_60per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Val_60per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Val_60per/\")\n",
        "Train_Dataset_name=\"Flux_train_60per\"\n",
        "Test_Dataset_name=\"Flux_val_60per\"\n",
        "Class_name=[\"litter\"]\n",
        "MetadataCatalog.get(Train_Dataset_name).set(thing_classes=Class_name)\n",
        "MetadataCatalog.get(Test_Dataset_name).set(thing_classes=Class_name)\n",
        "\n",
        "for filename in files:\n",
        "        print(\"#################\", filename, \"################\")\n",
        "        head, sep, tail = filename.partition('.pth')\n",
        "        if str(sep) == '.pth':\n",
        "          new_folder_name = head  # build the new name\n",
        "        model_checkpoint_path = os.path.join(files_path, filename)\n",
        "        detection_model = AutoDetectionModel.from_pretrained(\n",
        "          model_type='detectron2',\n",
        "          model_path=model_checkpoint_path,\n",
        "          config_path=model_config_path,\n",
        "          confidence_threshold=0.9,\n",
        "          # image_size=1333,\n",
        "          device=\"cuda:0\",\n",
        "          )\n",
        "        # do not generate the output_dir, the code will do it automatically\n",
        "        output_dir = os.path.join(ori_output_dir, new_folder_name)\n",
        "        # define slicing conf.\n",
        "        slice_height = 1920\n",
        "        slice_width = 1920\n",
        "        overlap_height_ratio = 0.2\n",
        "        overlap_width_ratio = 0.2\n",
        "        result = predict(\n",
        "          detection_model = detection_model,\n",
        "          source = source_image_dir,\n",
        "          slice_height = slice_height,\n",
        "          slice_width = slice_width,\n",
        "          overlap_height_ratio = overlap_height_ratio,\n",
        "          overlap_width_ratio = overlap_width_ratio,\n",
        "          project = output_dir,\n",
        "          postprocess_type = 'NMS', # dDefault is 'GREEDYNMM'.\n",
        "          postprocess_match_metric = 'IOU',\n",
        "          postprocess_match_threshold = 0.5, # NMS_IoU_threshold\n",
        "          visual_text_size = 3 # float\n",
        "          )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SL_20per on 1209 with litter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "files_path = r\"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/20per_10_runs/\"\n",
        "files = os.listdir(files_path)\n",
        "model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/SL_20per_1/config.yaml\"\n",
        "\n",
        "test_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/images_with_litter/\"\n",
        "\n",
        "# test dataset (with annotations)\n",
        "test_annotation_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/annotations/1209.json\"\n",
        "\n",
        "ori_output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/Pred/SL_20per/SA_1920_Conf_0.9/With_litter\"\n",
        "\n",
        "# Flux_train_20per\n",
        "register_coco_instances(\"Flux_train_20per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Train_20per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Train_20per/\")\n",
        "register_coco_instances(\"Flux_val_20per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Val_20per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Val_20per/\")\n",
        "Train_Dataset_name=\"Flux_train_20per\"\n",
        "Test_Dataset_name=\"Flux_val_20per\"\n",
        "Class_name=[\"litter\"]\n",
        "MetadataCatalog.get(Train_Dataset_name).set(thing_classes=Class_name)\n",
        "MetadataCatalog.get(Test_Dataset_name).set(thing_classes=Class_name)\n",
        "\n",
        "\n",
        "for filename in files:\n",
        "    print(\"#################\", filename, \"################\")\n",
        "    head, sep, tail = filename.partition('.pth')\n",
        "    if str(sep) == '.pth':\n",
        "        new_folder_name = head  # build the new name\n",
        "    model_checkpoint_path = os.path.join(files_path, filename)\n",
        "    detection_model = AutoDetectionModel.from_pretrained(\n",
        "          model_type='detectron2',\n",
        "          model_path=model_checkpoint_path,\n",
        "          config_path=model_config_path,\n",
        "          confidence_threshold=0.9,\n",
        "          # image_size=1333,\n",
        "          device=\"cuda:0\",\n",
        "          )\n",
        "    # do not generate the output_dir, the code will do it automatically\n",
        "    output_dir = os.path.join(ori_output_dir, new_folder_name)\n",
        "    # define slicing conf.\n",
        "    slice_height = 1920\n",
        "    slice_width = 1920\n",
        "    overlap_height_ratio = 0.2\n",
        "    overlap_width_ratio = 0.2\n",
        "    predict(\n",
        "          detection_model = detection_model,\n",
        "          source = test_image_dir,\n",
        "          slice_height = slice_height,\n",
        "          slice_width = slice_width,\n",
        "          overlap_height_ratio = overlap_height_ratio,\n",
        "          overlap_width_ratio = overlap_width_ratio,\n",
        "          project = output_dir,\n",
        "          dataset_json_path = test_annotation_path,\n",
        "          postprocess_type = 'NMS', # dDefault is 'GREEDYNMM'.\n",
        "          postprocess_match_metric = 'IOU',\n",
        "          postprocess_match_threshold = 0.5, # NMS_IoU_threshold\n",
        "          visual_text_size = 3 # float\n",
        "          # visual_bbox_thickness = None  # init\n",
        "          )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SL_20per on 1209 with no litter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "files_path = r\"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/20per_10_runs/\"\n",
        "files = os.listdir(files_path)\n",
        "model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/SL/SL_20per_1/config.yaml\"\n",
        "\n",
        "source_image_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/images_no_litter/\"  # 1209\n",
        "\n",
        "ori_output_dir = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/Pred/SL_20per/SA_1920_Conf_0.9/No_litter\"  # 1209\n",
        "\n",
        "# Flux_train_20per\n",
        "register_coco_instances(\"Flux_train_20per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Train_20per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Train_20per/\")\n",
        "register_coco_instances(\"Flux_val_20per\", {}, \"/scratch/tjian/Data/Flux/labeled_images_new/annotations/Val_20per.json\", \"/scratch/tjian/Data/Flux/labeled_images_new/Val_20per/\")\n",
        "Train_Dataset_name=\"Flux_train_20per\"\n",
        "Test_Dataset_name=\"Flux_val_20per\"\n",
        "Class_name=[\"litter\"]\n",
        "MetadataCatalog.get(Train_Dataset_name).set(thing_classes=Class_name)\n",
        "MetadataCatalog.get(Test_Dataset_name).set(thing_classes=Class_name)\n",
        "\n",
        "for filename in files:\n",
        "        print(\"#################\", filename, \"################\")\n",
        "        head, sep, tail = filename.partition('.pth')\n",
        "        if str(sep) == '.pth':\n",
        "          new_folder_name = head  # build the new name\n",
        "        model_checkpoint_path = os.path.join(files_path, filename)\n",
        "        detection_model = AutoDetectionModel.from_pretrained(\n",
        "          model_type='detectron2',\n",
        "          model_path=model_checkpoint_path,\n",
        "          config_path=model_config_path,\n",
        "          confidence_threshold=0.9,\n",
        "          # image_size=1333,\n",
        "          device=\"cuda:0\",\n",
        "          )\n",
        "        # do not generate the output_dir, the code will do it automatically\n",
        "        output_dir = os.path.join(ori_output_dir, new_folder_name)\n",
        "        # define slicing conf.\n",
        "        slice_height = 1920\n",
        "        slice_width = 1920\n",
        "        overlap_height_ratio = 0.2\n",
        "        overlap_width_ratio = 0.2\n",
        "        result = predict(\n",
        "          detection_model = detection_model,\n",
        "          source = source_image_dir,\n",
        "          slice_height = slice_height,\n",
        "          slice_width = slice_width,\n",
        "          overlap_height_ratio = overlap_height_ratio,\n",
        "          overlap_width_ratio = overlap_width_ratio,\n",
        "          project = output_dir,\n",
        "          postprocess_type = 'NMS', # dDefault is 'GREEDYNMM'.\n",
        "          postprocess_match_metric = 'IOU',\n",
        "          postprocess_match_threshold = 0.5, # NMS_IoU_threshold\n",
        "          visual_text_size = 3 # float\n",
        "          )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Detectron2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('sahi')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2680c47b11e1b3873482f0b7ab37c9292181f84f7b4413a77eb41d52d22c05d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
