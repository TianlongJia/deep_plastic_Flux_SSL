{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection evaluation\n",
    "\n",
    "Test a Detector on A Customized Dataset (here, I use the Faster RCNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from detectron2.data.datasets import register_coco_instances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model path\n",
    "model_checkpoint_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/RN50_25K_200e/Exp1/SSL_20per_5/model_best_78.4433.pth\"\n",
    "model_config_path = \"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/RN50_25K_200e/Exp1/SSL_20per_5/config.yaml\"\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_config_path)\n",
    "cfg.MODEL.WEIGHTS = model_checkpoint_path \n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register my custom test dataset\n",
    "\n",
    "dataset should be in COCO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register a test dataset\n",
    "register_coco_instances(\"Flux_test\", {}, \"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/annotations/1209.json\", \"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/images_with_litter/\")\n",
    "Test_Dataset_name=\"Flux_test\"\n",
    "Class_name=[\"litter\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Predict one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(\"/scratch/tjian/Data/Jakarta_coco/val/Grogol_Location_1_2018-04-30 16-00-00-05_cam6.jpg\")\n",
    "outputs = predictor(im)\n",
    "# print(outputs) # It will print num_instances, box location, scores, prediction labels\n",
    "\n",
    "v = Visualizer(im,\n",
    "               MetadataCatalog.get(Test_Dataset_name).set(thing_classes=Class_name),\n",
    "               instance_mode=ColorMode.SEGMENTATION,\n",
    "               scale=1.0\n",
    "               )\n",
    "\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))  # do not write \"gpu\"\n",
    "img=out.get_image()\n",
    "result=cv2.imwrite(r\"/scratch/tjian/Data/Jakarta_coco/Predictions_SSL/predict.jpg\", img)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Predict images in a folder and output No.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# define the folder path \n",
    "folder_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/images_no_litter/\"\n",
    "\n",
    "# define output folder of predicted images\n",
    "out_path = r\"/scratch/tjian/Data/Flux/TUD_Vietnam/1209/Pred/SSL_100per/No_SA/images_no_litter/\"\n",
    "\n",
    "# The total number of detections\n",
    "predictions = 0\n",
    "\n",
    "file_names = os.listdir(folder_path)\n",
    "for filename in file_names:\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            out_file_name= os.path.join(out_path, filename)\n",
    "            im = cv2.imread(image_path)\n",
    "            # start predicting\n",
    "            outputs = predictor(im)\n",
    "            print(outputs)\n",
    "            print(len(outputs[\"instances\"].get(\"pred_boxes\")))\n",
    "            predictions = predictions + len(outputs[\"instances\"].get(\"pred_boxes\"))\n",
    "            v = Visualizer(im,\n",
    "                           MetadataCatalog.get(Test_Dataset_name).set(thing_classes=Class_name),\n",
    "                           instance_mode=ColorMode.SEGMENTATION,\n",
    "                           scale=1.0\n",
    "                           )\n",
    "            out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))  # do not write \"gpu\"\n",
    "            img = out.get_image()\n",
    "            result = cv2.imwrite(out_file_name, img)\n",
    "\n",
    "print(\"Done\")\n",
    "print(\"The total number of detections: \", predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Test on a test dataset with labels\n",
    "\n",
    "Run a model to predict images with ground-truth labels and output the accuracy, e.g., AP50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "# Test\n",
    "save_evaluate_file_dir = r\"/scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/RN50_500K/Exp1/RN50_500K_200e/SSL_20per_7/test_results\"\n",
    "\n",
    "# create the \"save_evaluate_file_dir\" if they do not exist\n",
    "if not os.path.isdir(save_evaluate_file_dir):\n",
    "    os.mkdir(save_evaluate_file_dir)\n",
    "\n",
    "\n",
    "evaluator = COCOEvaluator(Test_Dataset_name, output_dir=save_evaluate_file_dir)\n",
    "val_loader = build_detection_test_loader(cfg, Test_Dataset_name)\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Output accuracy according to prediction and ground-truth files\n",
    "\n",
    "Compare predictions file (json file) and ground-truth files (json file), and output the accuracy, e.g., AP50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "# Load ground truth annotations\n",
    "coco_gt = COCO('/scratch/tjian/Data/GJO_SSL/test_1/test_PR/labels_coco/test.json')\n",
    "\n",
    "# Load detection results\n",
    "coco_dt = coco_gt.loadRes('/scratch/tjian/Data/GJO_SSL/test_1/test_PR/SSL_pred_results_NMS_0.5/coco_instances_results.json')\n",
    "\n",
    "# Create COCOEval object\n",
    "coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "\n",
    "# Run evaluation\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()\n",
    "\n",
    "# Get precision and recall values at different IoU thresholds\n",
    "precision = coco_eval.eval['precision']\n",
    "recall = coco_eval.eval['recall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Output confusion matrix on test dataset with annotations, i.e., TP, FP, FN\n",
    "\n",
    "See the \"main_Confusion_matrix_OD.ipynb\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) Calculate the FP on a dataset without litter annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# define the folder path \n",
    "folder_path = r\"/scratch/tjian/Data/Borgharen_test/labeled_data/0110/images_no_litter/\"\n",
    "\n",
    "file_names = os.listdir(folder_path)\n",
    "FP = 0\n",
    "for filename in file_names:\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            im = cv2.imread(image_path)\n",
    "            # start predicting\n",
    "            outputs = predictor(im)\n",
    "            # print(outputs)\n",
    "            # print(len(outputs[\"instances\"].get(\"pred_boxes\")))\n",
    "            FP = FP + len(outputs[\"instances\"].get(\"pred_boxes\"))\n",
    "\n",
    "print(\"FP: \", FP)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
