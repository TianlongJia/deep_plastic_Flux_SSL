{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fine-tune the model for object detection\n",
        "\n",
        "Note: the custom dataset must be in COCO form, i.e., the labels are saved in a json file"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1 Calculating the number of iterations in Detectron2\n",
        "\n",
        "Note: There is no concept of epoch in detectron2, so we need to calculate the number of iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NUM_GPUS = 1 \n",
        "IMS_PER_BATCH = 4 # Batch_size \n",
        "# TOTAL_NUM_IMAGES = 1243 # images in training dataset\n",
        "Epochs = 100\n",
        "\n",
        "# MAX_ITER = (Epochs * TOTAL_NUM_IMAGES) / (NUM_GPUS * IMS_PER_BATCH)\n",
        "# print(\"The number of itearations is: \", MAX_ITER)\n",
        "\n",
        "\n",
        "print(\"The number of itearations in GJO_train_2628 is: \", (Epochs * 2628) / (NUM_GPUS * IMS_PER_BATCH))\n",
        "print(\"The number of itearations in GJO_train_2076 is: \", (Epochs * 2076) / (NUM_GPUS * IMS_PER_BATCH))\n",
        "print(\"The number of itearations in GJO_train_1594 is: \", (Epochs * 1594) / (NUM_GPUS * IMS_PER_BATCH))\n",
        "print(\"The number of itearations in GJO_train_1013 is: \", (Epochs * 1013) / (NUM_GPUS * IMS_PER_BATCH))\n",
        "print(\"The number of itearations in GJO_train_527 is: \", (Epochs * 527) / (NUM_GPUS * IMS_PER_BATCH))\n",
        "print(\"The number of itearations in GJO_train_282 is: \", (Epochs * 282) / (NUM_GPUS * IMS_PER_BATCH))\n",
        "print(\"The number of itearations in GJO_train_124 is: \", (Epochs * 124) / (NUM_GPUS * IMS_PER_BATCH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of itearations in GJO_train_2628 is:  2700.0\n"
          ]
        }
      ],
      "source": [
        "NUM_GPUS = 1 \n",
        "IMS_PER_BATCH = 4 # Batch_size \n",
        "# TOTAL_NUM_IMAGES = 1243 # images in training dataset\n",
        "Epochs = 100\n",
        "\n",
        "# MAX_ITER = (Epochs * TOTAL_NUM_IMAGES) / (NUM_GPUS * IMS_PER_BATCH)\n",
        "# print(\"The number of itearations is: \", MAX_ITER)\n",
        "\n",
        "print(\"The number of itearations in GJO_train_2628 is: \", (Epochs * 108) / (NUM_GPUS * IMS_PER_BATCH))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3 Register fine-tuning dataset\n",
        "\n",
        "Register the dataset in the **tools/object_detection_benchmark_1.py** file, using the following example code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# register my custom dataset, if your dataset is in COCO format:\n",
        "       \n",
        "# Flux\n",
        "# register_coco_instances(\"Flux_train\", {}, \"/scratch/tjian/Data/Flux/labeled_images/annotations/train.json\", \"/scratch/tjian/Data/Flux/labeled_images/train/\")\n",
        "# register_coco_instances(\"Flux_val\", {}, \"/scratch/tjian/Data/Flux/labeled_images/annotations/val.json\", \"/scratch/tjian/Data/Flux/labeled_images/val/\")\n",
        "\n",
        "\n",
        "# 0609_1_round_SF\n",
        "register_coco_instances(\"0609_1_round_train\", {}, \"/scratch/tjian/Data/Flux/TUD_Vietnam/0609_1_round_SF/annotations/train.json\", \"/scratch/tjian/Data/Flux/TUD_Vietnam/0609_1_round_SF/train/\")\n",
        "register_coco_instances(\"0609_1_round_val\", {}, \"/scratch/tjian/Data/Flux/TUD_Vietnam/0609_1_round_SF/annotations/val.json\", \"/scratch/tjian/Data/Flux/TUD_Vietnam/0609_1_round_SF/val/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4 Define the metric \n",
        "\n",
        "Save the best model weights with a type of metric during validatingduring validating in the **tools/object_detection_benchmark_1.py** file, using the following example code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Choose the metric to validate the model\n",
        "metric_name=\"bbox/AP50\"\n",
        "# metric_name=\"bbox/AP\"\n",
        "# metric_name=\"bbox/AP75\"\n",
        "# metric_name=\"bbox/APs\"\n",
        "# metric_name=\"bbox/APm\"\n",
        "# metric_name=\"bbox/APl\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5 Fine-tune the model\n",
        "\n",
        "Using a Semi-supervised learning (5.1) or a supervised learning (5.2) method\n",
        "\n",
        "Note: Freeze the first 2 layers of ResNet: *MODEL.BACKBONE.FREEZE_AT 2*; Freeze the first 4 layers of ResNet: *MODEL.BACKBONE.FREEZE_AT 4*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YaUMDwMdzYHN"
      },
      "source": [
        "### 5.1 Semi-supervised learning\n",
        "\n",
        "Steps:\n",
        "\n",
        "(1) Load the ResNet weights pre-trained by self-supervised learning method (SimClR or SwAV), and generate the Faster R-CNN based on this backbone;\n",
        "\n",
        "(2) Modify the Faster R-CNN hyperparameters in \"/configs/config/benchmark/object_detection/COCOInstance/R50_C4_COCO/tiles_224/XXX.yaml\" file, especially the **dataset name**.\n",
        "\n",
        "(3) Fine-tune the FasterRCNN in a supervised learning method.\n",
        "\n",
        "Notice:\n",
        "\n",
        "If gpus=1, no.images=200, batch_size=4, and epochs=100, then \"SOLVER.MAX_ITER 5000\"  # 5000=(200/4)*100"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Self_supervised method: SwAV\n",
        "\n",
        "Note: you can modify **MODEL.BACKBONE.FREEZE_AT 2 (or 4)** parameter to define the first 2 (or 4) layers are frozen when fine-tuning"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### (1) Faster R-CNN with **ResNet50**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Self_supervised method: SwAV\n",
        "\n",
        "# Moded is trained on image tiles 224*224\n",
        "# gpu=1\n",
        "# num_epochs=100\n",
        "# batch_size=4\n",
        "# Fine-tune: F4\n",
        "\n",
        "# Pre-trian: RN50_300K_100e\n",
        "!python tools/object_detection_benchmark_1.py \\\n",
        "    --config-file /scratch/tjian/PythonProject/deep_plastic_Flux_SSL/configs/config/benchmark/object_detection/COCOInstance/R50_C4_COCO/tiles_224/Sliced_Fine/FRC_50.yaml \\\n",
        "     --num-gpus 1 SOLVER.MAX_ITER 2700 TEST.EVAL_PERIOD 27 SOLVER.IMS_PER_BATCH 4 MODEL.BACKBONE.FREEZE_AT 0 MODEL.WEIGHTS /scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/RN50_300K_100e/SSL_F4/model_best_86.1242.pth OUTPUT_DIR /scratch/tjian/PythonProject/deep_plastic_Flux_SSL/checkpoint/train_weights/0609_1_round_SF/\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### (2) Faster R-CNN with **ResNet101**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Moded is trained on image tiles 224*224\n",
        "# gpu=1\n",
        "# num_epochs=100\n",
        "# batch_size=4\n",
        "\n",
        "# Fine-tune: F4\n",
        "\n",
        "# Pre-trian: RN101_100K_100e\n",
        "!python tools/object_detection_benchmark_1.py \\\n",
        "    --config-file /scratch/tjian/PythonProject/deep_plastic_Flux_SSL/configs/config/benchmark/object_detection/COCOInstance/R50_C4_COCO/tiles_224/Sliced_Fine/FRC_101.yaml \\\n",
        "     --num-gpus 1 SOLVER.MAX_ITER 2700 TEST.EVAL_PERIOD 27 SOLVER.IMS_PER_BATCH 4 MODEL.BACKBONE.FREEZE_AT 4 MODEL.WEIGHTS XXX OUTPUT_DIR XXXX\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Train SimCLR on 1 gpu V0.1.6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "DP_SSL_gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "dbbe8bc68948aa4d867a11751be32290236d08d1e79f7c977f6ca048c3b7322a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
